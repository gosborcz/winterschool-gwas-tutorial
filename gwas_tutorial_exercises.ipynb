{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-title",
   "metadata": {},
   "source": ["# GWAS Tutorial (Exercise Version): Data Exploration, QC & Association Analysis\n\nThis is the **exercise version** of the tutorial. Key code cells have been partially or fully replaced with stubs â€” your job is to fill them in.\n\nAll computation (Hail aggregations, QC functions, GWAS) is provided. You write the **visualisations** and **regression calls**.\n\n> If you get stuck, compare with the [complete version](https://colab.research.google.com/github/gosborcz/winterschool-gwas-tutorial/blob/main/gwas_tutorial.ipynb)."]
  },
  {
   "cell_type": "markdown",
   "id": "md-setup-hdr",
   "metadata": {},
   "source": ["## 1. Setup"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-setup",
   "metadata": {},
   "outputs": [],
   "source": ["# Install Java (Hail's Spark backend) and Hail\n!apt-get install -y openjdk-11-jdk-headless -q\n!pip install hail -q\n\nimport hail as hl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom collections import Counter\nfrom pprint import pprint\n\nhl.init()\nfrom hail.plot import show\nhl.plot.output_notebook()\n\nimport os\nos.makedirs('data', exist_ok=True)\nhl.utils.get_1kg('data/')\n\nhl.import_vcf('data/1kg.vcf.bgz').write('data/1kg.mt', overwrite=True)\nmt = hl.read_matrix_table('data/1kg.mt')\n\ntable = hl.import_table('data/1kg_annotations.txt', impute=True).key_by('Sample')\nmt = mt.annotate_cols(pheno=table[mt.s])\nprint('Loaded: %d variants x %d samples' % mt.count())"]
  },
  {
   "cell_type": "markdown",
   "id": "md-section1",
   "metadata": {},
   "source": ["## 2. Data Exploration"]
  },
  {
   "cell_type": "markdown",
   "id": "md-mt-structure",
   "metadata": {},
   "source": ["### The MatrixTable\n\nHail stores genomic data in a **MatrixTable** â€” a 2D structure where:\n\n```\n              Sample1  Sample2  Sample3  ...\n chr1:100 A/T   0/1      0/0      1/1\n chr1:200 G/C   0/0      0/1      0/1\n    ...          ...      ...      ...\n```\n\n- **Rows** = variants (locus + alleles)\n- **Columns** = samples (sample ID `s`)\n- **Entries** = genotype calls (GT, DP, GQ, AD, PL)\n- **Row fields** = variant INFO annotations\n- **Column fields** = sample metadata"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-rows",
   "metadata": {},
   "outputs": [],
   "source": ["mt.rows().select().show(5)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-entries",
   "metadata": {},
   "outputs": [],
   "source": ["mt.entry.take(3)"]
  },
  {
   "cell_type": "markdown",
   "id": "md-annotations-hdr",
   "metadata": {},
   "source": ["### Sample Annotations"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-show-table",
   "metadata": {},
   "outputs": [],
   "source": ["table.show(5, width=120)"]
  },
  {
   "cell_type": "markdown",
   "id": "md-pheno-hdr",
   "metadata": {},
   "source": ["### Phenotype & Population Overview"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-pop-counts",
   "metadata": {},
   "outputs": [],
   "source": ["pop_counts = mt.aggregate_cols(hl.agg.counter(mt.pheno.SuperPopulation))\npprint(pop_counts)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-pop-bar",
   "metadata": {},
   "outputs": [],
   "source": ["pops = sorted(pop_counts.keys())\ncounts = [pop_counts[p] for p in pops]\n\nfig, ax = plt.subplots(figsize=(8, 4))\n# YOUR CODE HERE: bar chart of pops vs counts, label axes, annotate bars with counts\n"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-caffeine",
   "metadata": {},
   "outputs": [],
   "source": ["pprint(mt.aggregate_cols(hl.agg.stats(mt.pheno.CaffeineConsumption)))"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-caffeine-hist",
   "metadata": {},
   "outputs": [],
   "source": ["# YOUR CODE HERE: plot the distribution of CaffeineConsumption\n# Hint: use hl.plot.histogram(mt.pheno.CaffeineConsumption, bins=30, title=..., legend=...)\n"]
  },
  {
   "cell_type": "markdown",
   "id": "md-variants-hdr",
   "metadata": {},
   "source": ["### Variant Exploration"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-snp-types",
   "metadata": {},
   "outputs": [],
   "source": ["snp_counts = mt.aggregate_rows(\n    hl.agg.counter(hl.Struct(ref=mt.alleles[0], alt=mt.alleles[1]))\n)\nprint('Top 10 allele changes:')\nfor k, v in Counter(snp_counts).most_common(10):\n    print('  %s -> %s: %d' % (k.ref, k.alt, v))"]
  },
  {
   "cell_type": "markdown",
   "id": "md-afs-hdr",
   "metadata": {},
   "source": ["#### Allele Frequency Spectrum\n\nMost variants are rare â€” an L-shaped AFS is the hallmark of healthy genetic data under neutral evolution."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-afs",
   "metadata": {},
   "outputs": [],
   "source": ["afs = mt.aggregate_rows(hl.agg.hist(mt.info.AF[0], 0, 1.0, 50))\nedges, freq = afs.bin_edges, afs.bin_freq\nmids = [(a + b) / 2 for a, b in zip(edges, edges[1:])]\nwidth = (edges[1] - edges[0]) * 0.9\n\nfig, ax = plt.subplots(figsize=(9, 4))\n# YOUR CODE HERE: bar chart with mids on x-axis, freq on y-axis, label axes\n# Hint: ax.bar(mids, freq, width=width, ...)\n"]
  },
  {
   "cell_type": "markdown",
   "id": "md-chrom-hdr",
   "metadata": {},
   "source": ["#### Variant Density by Chromosome"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-chrom",
   "metadata": {},
   "outputs": [],
   "source": ["chrom_counts = mt.aggregate_rows(hl.agg.counter(mt.locus.contig))\n\ndef chrom_sort_key(c):\n    n = c.replace('chr', '')\n    return (0, int(n)) if n.isdigit() else (1, n)\n\nchroms = sorted(chrom_counts.keys(), key=chrom_sort_key)\ncnts = [chrom_counts[c] for c in chroms]\n\nfig, ax = plt.subplots(figsize=(13, 4))\n# YOUR CODE HERE: bar chart of variants per chromosome\n# Hint: use ax.bar(range(len(chroms)), cnts, ...) then ax.set_xticks + ax.set_xticklabels\n"]
  },
  {
   "cell_type": "markdown",
   "id": "md-gt-hdr",
   "metadata": {},
   "source": ["#### Genotype Distribution\n\nBecause most variants are rare, the vast majority of entries should be homozygous reference (0/0)."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-gt-dist",
   "metadata": {},
   "outputs": [],
   "source": ["gt_counts = mt.aggregate_entries(hl.agg.counter(mt.GT.n_alt_alleles()))\n\nlabels = ['Hom Ref (0/0)', 'Het (0/1)', 'Hom Alt (1/1)']\nvalues = [gt_counts.get(k, 0) for k in range(3)]\ntotal = sum(values)\ncolors = ['#4e9af1', '#f4a261', '#e76f51']\n\nfig, (ax, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n# YOUR CODE HERE:\n# ax: bar chart of labels vs values\n# ax2: pie chart with autopct='%1.1f%%'\n# Also print counts + percentages below the plot\n"]
  },
  {
   "cell_type": "markdown",
   "id": "md-ex1",
   "metadata": {},
   "source": ["---\n**ðŸ” Exercise 1:** The bar chart above shows counts for the 5 super-populations. Modify it to show the breakdown by the more specific `Population` field. How many distinct populations are in this dataset?\n\n> *Hint: change `mt.pheno.SuperPopulation` â†’ `mt.pheno.Population` in the `agg.counter` call and re-run the bar chart.*"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-ex1",
   "metadata": {},
   "outputs": [],
   "source": ["# Exercise 1 â€” your code here\n"]
  },
  {
   "cell_type": "markdown",
   "id": "md-section2",
   "metadata": {},
   "source": ["## 3. Quality Control"]
  },
  {
   "cell_type": "markdown",
   "id": "md-sample-qc-hdr",
   "metadata": {},
   "source": ["### Sample QC\n\n`hl.sample_qc()` computes per-sample metrics:\n\n| Metric | Meaning |\n|---|---|\n| `call_rate` | Fraction of non-missing genotype calls |\n| `dp_stats.mean` | Mean read depth |\n| `gq_stats.mean` | Mean genotype quality |"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-sample-qc",
   "metadata": {},
   "outputs": [],
   "source": ["mt = hl.sample_qc(mt)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-dp-hist",
   "metadata": {},
   "outputs": [],
   "source": ["p = hl.plot.histogram(mt.sample_qc.dp_stats.mean, range=(0, 30), bins=30,\n                      title='Mean Read Depth per Sample', legend='Mean DP')\nshow(p)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-callrate-hist",
   "metadata": {},
   "outputs": [],
   "source": ["p = hl.plot.histogram(mt.sample_qc.call_rate, range=(0.88, 1.0), bins=30,\n                      title='Call Rate per Sample', legend='Call Rate')\nshow(p)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-gq-hist",
   "metadata": {},
   "outputs": [],
   "source": ["p = hl.plot.histogram(mt.sample_qc.gq_stats.mean, range=(10, 70), bins=30,\n                      title='Mean GQ per Sample', legend='Mean GQ')\nshow(p)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-dp-cr-scatter",
   "metadata": {},
   "outputs": [],
   "source": ["p = hl.plot.scatter(mt.sample_qc.dp_stats.mean, mt.sample_qc.call_rate,\n                    xlabel='Mean DP', ylabel='Call Rate',\n                    title='Mean Depth vs. Call Rate')\nshow(p)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-sample-filter",
   "metadata": {},
   "outputs": [],
   "source": ["n_before = mt.count_cols()\nmt = mt.filter_cols((mt.sample_qc.dp_stats.mean >= 4) & (mt.sample_qc.call_rate >= 0.97))\nprint('Samples: %d â†’ %d (removed %d)' % (n_before, mt.count_cols(), n_before - mt.count_cols()))"]
  },
  {
   "cell_type": "markdown",
   "id": "md-ab-hdr",
   "metadata": {},
   "source": ["### Allelic Balance Filter\n\nThe **allelic balance (AB)** â€” fraction of reads supporting the alt allele â€” should be:\n- ~0 for hom ref (0/0)\n- ~0.5 for het (0/1)\n- ~1 for hom alt (1/1)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-ab-filter",
   "metadata": {},
   "outputs": [],
   "source": ["ab = mt.AD[1] / hl.sum(mt.AD)\nfilter_ab = (\n    (mt.GT.is_hom_ref() & (ab <= 0.1)) |\n    (mt.GT.is_het()     & (ab >= 0.25) & (ab <= 0.75)) |\n    (mt.GT.is_hom_var() & (ab >= 0.9))\n)\nfraction_filtered = mt.aggregate_entries(hl.agg.fraction(~filter_ab))\nprint('Setting %.2f%% of entries to missing (failed AB filter).' % (fraction_filtered * 100))\nmt = mt.filter_entries(filter_ab)"]
  },
  {
   "cell_type": "markdown",
   "id": "md-ex2",
   "metadata": {},
   "source": ["---\n**ðŸ” Exercise 2:** The current het allelic balance window is **0.25â€“0.75**. What fraction of entries would *additionally* be removed if you tightened it to **0.30â€“0.70**?\n\n> *Hint: compute `hl.agg.fraction(~filter_ab_strict)` using the stricter condition on `mt` before calling `filter_entries`.*"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-ex2",
   "metadata": {},
   "outputs": [],
   "source": ["# Exercise 2 â€” your code here\n"]
  },
  {
   "cell_type": "markdown",
   "id": "md-variant-qc-hdr",
   "metadata": {},
   "source": ["### Variant QC\n\n`hl.variant_qc()` computes per-variant metrics:\n\n| Metric | Meaning |\n|---|---|\n| `AF[1]` | Alternate allele frequency in this dataset |\n| `call_rate` | Fraction of samples with a call |\n| `p_value_hwe` | Hardy-Weinberg equilibrium test p-value |"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-variant-qc",
   "metadata": {},
   "outputs": [],
   "source": ["mt = hl.variant_qc(mt)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-maf-dist",
   "metadata": {},
   "outputs": [],
   "source": ["af_hist = mt.aggregate_rows(hl.agg.hist(mt.variant_qc.AF[1], 0, 0.5, 50))\nedges, freq = af_hist.bin_edges, af_hist.bin_freq\nmids = [(a + b) / 2 for a, b in zip(edges, edges[1:])]\nwidth = (edges[1] - edges[0]) * 0.9\n\nfig, ax = plt.subplots(figsize=(9, 4))\n# YOUR CODE HERE: bar chart of MAF distribution\n# Add a vertical dashed red line at x=0.01 to mark the filter threshold\n# Hint: ax.axvline(x=0.01, color='red', linestyle='--', label='AF = 1% filter')\n"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-hwe-dist",
   "metadata": {},
   "outputs": [],
   "source": ["hwe_hist = mt.aggregate_rows(\n    hl.agg.filter(hl.is_defined(mt.variant_qc.p_value_hwe),\n                  hl.agg.hist(-hl.log10(mt.variant_qc.p_value_hwe), 0, 10, 40))\n)\nedges, freq = hwe_hist.bin_edges, hwe_hist.bin_freq\nmids = [(a + b) / 2 for a, b in zip(edges, edges[1:])]\nwidth = (edges[1] - edges[0]) * 0.9\n\nfig, ax = plt.subplots(figsize=(9, 4))\n# YOUR CODE HERE: bar chart of -log10(HWE p-value) distribution\n# Add a vertical dashed red line at x=6 to mark the filter threshold (p=1e-6)\n"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-variant-filter",
   "metadata": {},
   "outputs": [],
   "source": ["n_vars_before = mt.count_rows()\nmt = mt.filter_rows((mt.variant_qc.AF[1] > 0.01) & (mt.variant_qc.p_value_hwe > 1e-6))\nn_vars_after = mt.count_rows()\nprint('Variants: %d â†’ %d (removed %d, %.1f%%)' % (\n    n_vars_before, n_vars_after,\n    n_vars_before - n_vars_after,\n    100 * (n_vars_before - n_vars_after) / n_vars_before\n))"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-before-after",
   "metadata": {},
   "outputs": [],
   "source": ["fig, ax = plt.subplots(figsize=(6, 4))\n# YOUR CODE HERE: bar chart comparing n_vars_before vs n_vars_after\n# Label bars with the exact counts\n"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-final-count",
   "metadata": {},
   "outputs": [],
   "source": ["n_variants, n_samples = mt.count()\nprint('After QC: %d variants x %d samples' % (n_variants, n_samples))"]
  },
  {
   "cell_type": "markdown",
   "id": "md-section3",
   "metadata": {},
   "source": ["## 4. Association Analysis"]
  },
  {
   "cell_type": "markdown",
   "id": "md-pca-hdr",
   "metadata": {},
   "source": ["### Population Stratification â€” PCA\n\nThe 1000 Genomes dataset spans 5 continental populations (AFR, AMR, EAS, EUR, SAS). We compute **Principal Components (PCs)** to capture ancestry and include them as covariates."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-pca-run",
   "metadata": {},
   "outputs": [],
   "source": ["eigenvalues, pcs, _ = hl.hwe_normalized_pca(mt.GT)\npprint(eigenvalues[:5])\nmt = mt.annotate_cols(scores=pcs[mt.s].scores)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-pca-plot",
   "metadata": {},
   "outputs": [],
   "source": ["# YOUR CODE HERE: scatter plot of PC1 vs PC2, coloured by SuperPopulation\n# Hint: use hl.plot.scatter(mt.scores[0], mt.scores[1], label=mt.pheno.SuperPopulation, ...)\n# then show(p)\n"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-pca-pc3",
   "metadata": {},
   "outputs": [],
   "source": ["# YOUR CODE HERE: scatter plot of PC2 vs PC3, coloured by SuperPopulation\n"]
  },
  {
   "cell_type": "markdown",
   "id": "md-naive-gwas-hdr",
   "metadata": {},
   "source": ["### Naive GWAS (no covariates)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-naive-gwas",
   "metadata": {},
   "outputs": [],
   "source": ["gwas_naive = hl.linear_regression_rows(\n    y=mt.pheno.CaffeineConsumption,\n    x=mt.GT.n_alt_alleles(),\n    covariates=[1.0]\n)\np = hl.plot.qq(gwas_naive.p_value, title='QQ Plot â€” naive (no covariates)')\nshow(p)\np = hl.plot.manhattan(gwas_naive.p_value, title='Manhattan Plot â€” naive (no covariates)')\nshow(p)"]
  },
  {
   "cell_type": "markdown",
   "id": "md-lambda-explain",
   "metadata": {},
   "source": ["**Genomic inflation factor (Î»)** is shown in the QQ plot:\n- Î» â‰ˆ 1.0 â†’ well-calibrated\n- Î» > 1.05 â†’ inflation (likely population stratification)\n- Î» < 1.0 â†’ deflation"]
  },
  {
   "cell_type": "markdown",
   "id": "md-corrected-gwas-hdr",
   "metadata": {},
   "source": ["### Corrected GWAS (sex + PC1â€“3 as covariates)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-corrected-gwas",
   "metadata": {},
   "outputs": [],
   "source": ["# YOUR CODE HERE: run hl.linear_regression_rows with sex and PC1-3 as covariates\n# covariates=[1.0, mt.pheno.isFemale, mt.scores[0], mt.scores[1], mt.scores[2]]\n# Then plot QQ and Manhattan plots\ngwas = None  # replace with your linear_regression_rows call\n"]
  },
  {
   "cell_type": "markdown",
   "id": "md-top-hits-hdr",
   "metadata": {},
   "source": ["### Top Hits"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-top-hits",
   "metadata": {},
   "outputs": [],
   "source": ["gwas.order_by(gwas.p_value).select('p_value', 'beta', 'standard_error', 't_stat').show(20, width=120)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-top-hits-viz",
   "metadata": {},
   "outputs": [],
   "source": ["top = gwas.order_by(gwas.p_value).take(20)\nbetas = np.array([r.beta for r in top])\nses   = np.array([r.standard_error for r in top])\nlabels = ['%s/%s' % (r.locus, r.alleles[1]) for r in top]\n\nfig, ax = plt.subplots(figsize=(8, 7))\ny = np.arange(len(top))\nax.errorbar(betas, y, xerr=1.96 * ses, fmt='o', color='steelblue',\n            capsize=3, linewidth=1, markersize=5)\nax.axvline(0, color='grey', linestyle='--', linewidth=1)\nax.set_yticks(y)\nax.set_yticklabels(labels, fontsize=8)\nax.set(xlabel='Effect size (beta) Â± 95% CI', title='Top 20 Variants by P-value')\nax.invert_yaxis()\nplt.tight_layout()\nplt.show()"]
  },
  {
   "cell_type": "markdown",
   "id": "md-ex3",
   "metadata": {},
   "source": ["---\n**ðŸ” Exercise 3:** Run a **logistic GWAS** for the binary `PurpleHair` phenotype. Do the top hits overlap with caffeine?\n\n> *Starter code:*\n> ```python\n> gwas_binary = hl.logistic_regression_rows(\n>     test='wald',\n>     y=mt.pheno.PurpleHair,\n>     x=mt.GT.n_alt_alleles(),\n>     covariates=[1.0, mt.pheno.isFemale, mt.scores[0], mt.scores[1], mt.scores[2]]\n> )\n> ```"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-ex3",
   "metadata": {},
   "outputs": [],
   "source": ["# Exercise 3 â€” your code here\n"]
  },
  {
   "cell_type": "markdown",
   "id": "md-summary",
   "metadata": {},
   "source": ["## Summary\n\nIn this tutorial you:\n\n- âœ… Downloaded and imported the 1000 Genomes VCF into a Hail MatrixTable\n- âœ… Explored the dataset: MatrixTable structure, population composition, allele frequency spectrum, genotype distribution\n- âœ… Applied sample QC (depth, call rate), allelic balance filtering, and variant QC (MAF, HWE)\n- âœ… Ran PCA to capture population structure\n- âœ… Compared a naive vs. covariate-corrected GWAS, and observed the effect of stratification on Î»\n- âœ… Identified and visualised the top associated variants"]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
