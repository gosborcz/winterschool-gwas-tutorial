{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-title",
   "metadata": {},
   "source": ["# GWAS Tutorial — Part 2: Quality Control\n\nBefore running a GWAS, we must remove low-quality samples and variants. Poor-quality data leads to spurious associations and inflated p-values. This notebook covers:\n\n1. **Sample QC** — identify and remove poor-quality individuals\n2. **Genotype-level filtering** — remove unreliable genotype calls\n3. **Variant QC** — filter rare variants and Hardy-Weinberg violations\n\n> **Prerequisites:** Run [Part 1](https://colab.research.google.com/github/gosborcz/winterschool-gwas-tutorial/blob/main/01_data_and_exploration.ipynb) first, or use the Setup cell below to start fresh."]
  },
  {
   "cell_type": "markdown",
   "id": "md-setup-header",
   "metadata": {},
   "source": ["## Setup\n\nRun this cell at the start of every session. It installs Hail, downloads the data if needed, and loads the annotated MatrixTable."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-setup",
   "metadata": {},
   "outputs": [],
   "source": ["!apt-get install -y openjdk-11-jdk-headless -q\n!pip install hail -q\n\nimport hail as hl\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nfrom pprint import pprint\n\nhl.init()\nfrom hail.plot import show\nhl.plot.output_notebook()\n\n# Download data if not already present\nimport os\nos.makedirs('data', exist_ok=True)\nif not os.path.exists('data/1kg.mt'):\n    hl.utils.get_1kg('data/')\n    hl.import_vcf('data/1kg.vcf.bgz').write('data/1kg.mt', overwrite=True)\n\n# Load and annotate\ntable = hl.import_table('data/1kg_annotations.txt', impute=True).key_by('Sample')\nmt = hl.read_matrix_table('data/1kg.mt')\nmt = mt.annotate_cols(pheno=table[mt.s])\nprint('Loaded: %d variants x %d samples' % mt.count())"]
  },
  {
   "cell_type": "markdown",
   "id": "md-sample-qc-header",
   "metadata": {},
   "source": ["## 1. Sample QC\n\n`hl.sample_qc()` computes per-sample quality metrics and adds them to the column fields under `sample_qc`. Key metrics include:\n\n| Metric | Meaning |\n|---|---|\n| `call_rate` | Fraction of variants with a genotype call (non-missing) |\n| `dp_stats.mean` | Mean read depth across all called genotypes |\n| `gq_stats.mean` | Mean genotype quality score |\n| `n_het` | Number of heterozygous calls |\n\nSamples with low call rate or low depth are flagged for removal."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-sample-qc",
   "metadata": {},
   "outputs": [],
   "source": ["mt = hl.sample_qc(mt)\nmt.col.describe()"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-dp-hist",
   "metadata": {},
   "outputs": [],
   "source": ["# Mean read depth per sample\np = hl.plot.histogram(mt.sample_qc.dp_stats.mean, range=(0, 30), bins=30,\n                      title='Mean Read Depth per Sample', legend='Mean DP')\nshow(p)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-callrate-hist",
   "metadata": {},
   "outputs": [],
   "source": ["# Call rate per sample (fraction of non-missing genotypes)\np = hl.plot.histogram(mt.sample_qc.call_rate, range=(0.88, 1.0), bins=30,\n                      title='Call Rate per Sample', legend='Call Rate')\nshow(p)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-gq-hist",
   "metadata": {},
   "outputs": [],
   "source": ["# Mean genotype quality per sample\np = hl.plot.histogram(mt.sample_qc.gq_stats.mean, range=(10, 70), bins=30,\n                      title='Mean Genotype Quality per Sample', legend='Mean GQ')\nshow(p)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-dp-cr-scatter",
   "metadata": {},
   "outputs": [],
   "source": ["# Scatter: mean depth vs. call rate — samples failing either threshold will appear in the low-left corner\np = hl.plot.scatter(mt.sample_qc.dp_stats.mean, mt.sample_qc.call_rate,\n                    xlabel='Mean DP', ylabel='Call Rate',\n                    title='Mean Depth vs. Call Rate')\nshow(p)"]
  },
  {
   "cell_type": "markdown",
   "id": "md-sample-filter",
   "metadata": {},
   "source": ["### Sample Filtering\n\nBased on the distributions above, we apply two filters:\n- **Mean depth ≥ 4** — removes samples with insufficient sequencing coverage\n- **Call rate ≥ 0.97** — removes samples with >3% missing genotypes"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-sample-filter",
   "metadata": {},
   "outputs": [],
   "source": ["n_before = mt.count_cols()\nmt = mt.filter_cols((mt.sample_qc.dp_stats.mean >= 4) & (mt.sample_qc.call_rate >= 0.97))\nn_after = mt.count_cols()\nprint('Samples before filter: %d' % n_before)\nprint('Samples after filter:  %d' % n_after)\nprint('Removed: %d samples' % (n_before - n_after))"]
  },
  {
   "cell_type": "markdown",
   "id": "md-ab-filter",
   "metadata": {},
   "source": ["## 2. Allelic Balance Filter\n\nEven within a passing sample, individual genotype calls can be unreliable. The **allelic balance (AB)** — the fraction of reads supporting the alternate allele — should be:\n\n- ~0 for homozygous reference calls (0/0)\n- ~0.5 for heterozygous calls (0/1)\n- ~1.0 for homozygous alternate calls (1/1)\n\nCalls with allelic balance far from these expected values are filtered out (set to missing)."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-ab-filter",
   "metadata": {},
   "outputs": [],
   "source": ["ab = mt.AD[1] / hl.sum(mt.AD)\n\nfilter_condition_ab = (\n    (mt.GT.is_hom_ref() & (ab <= 0.1)) |\n    (mt.GT.is_het() & (ab >= 0.25) & (ab <= 0.75)) |\n    (mt.GT.is_hom_var() & (ab >= 0.9))\n)\n\nfraction_filtered = mt.aggregate_entries(hl.agg.fraction(~filter_condition_ab))\nprint('Filtering %.2f%% of entries (setting to missing).' % (fraction_filtered * 100))\nmt = mt.filter_entries(filter_condition_ab)"]
  },
  {
   "cell_type": "markdown",
   "id": "md-variant-qc-header",
   "metadata": {},
   "source": ["## 3. Variant QC\n\n`hl.variant_qc()` computes per-variant quality metrics. Key metrics:\n\n| Metric | Meaning |\n|---|---|\n| `AF[1]` | Allele frequency of the alternate allele in this dataset |\n| `call_rate` | Fraction of samples with a genotype call at this variant |\n| `p_value_hwe` | Hardy-Weinberg equilibrium test p-value |\n| `n_het` | Number of heterozygous calls |\n\nWe filter on allele frequency and HWE."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-variant-qc",
   "metadata": {},
   "outputs": [],
   "source": ["mt = hl.variant_qc(mt)\nmt.row.describe()"]
  },
  {
   "cell_type": "markdown",
   "id": "md-enhanced-qc",
   "metadata": {},
   "source": ["### Enhanced QC Visualizations\n\nBefore applying variant filters, let's visualize the distributions to understand where we set thresholds."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-maf-dist",
   "metadata": {},
   "outputs": [],
   "source": ["# Minor allele frequency distribution\n# AF[1] is the alt allele frequency; MAF = min(AF, 1-AF)\naf_hist = mt.aggregate_rows(hl.agg.hist(mt.variant_qc.AF[1], 0, 0.5, 50))\n\nedges = af_hist.bin_edges\nwidths = [(edges[i+1] - edges[i]) * 0.9 for i in range(len(af_hist.bin_freq))]\nmids = [(edges[i] + edges[i+1]) / 2 for i in range(len(af_hist.bin_freq))]\n\nfig, ax = plt.subplots(figsize=(9, 4))\nax.bar(mids, af_hist.bin_freq, width=widths, color='steelblue', edgecolor='white', linewidth=0.5)\nax.axvline(x=0.01, color='red', linestyle='--', linewidth=1.5, label='AF = 1%% filter')\nax.set_xlabel('Alternate Allele Frequency (AF)', fontsize=12)\nax.set_ylabel('Number of Variants', fontsize=12)\nax.set_title('Minor Allele Frequency Distribution (before filtering)', fontsize=14)\nax.legend()\nplt.tight_layout()\nplt.show()\n\nlow_freq = sum(f for m, f in zip(mids, af_hist.bin_freq) if m < 0.01)\ntotal = sum(af_hist.bin_freq)\nprint('Variants with AF < 1%%: %d (%.1f%%)' % (low_freq, 100 * low_freq / total if total else 0))"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-hwe-dist",
   "metadata": {},
   "outputs": [],
   "source": ["# Hardy-Weinberg Equilibrium p-value distribution\n# Under HWE, genotype frequencies follow the expected binomial proportions.\n# Very low p-values (< 1e-6) often indicate genotyping errors or population structure.\nhwe_hist = mt.aggregate_rows(\n    hl.agg.filter(hl.is_defined(mt.variant_qc.p_value_hwe),\n                  hl.agg.hist(-hl.log10(mt.variant_qc.p_value_hwe), 0, 10, 40))\n)\n\nedges = hwe_hist.bin_edges\nwidths = [(edges[i+1] - edges[i]) * 0.9 for i in range(len(hwe_hist.bin_freq))]\nmids = [(edges[i] + edges[i+1]) / 2 for i in range(len(hwe_hist.bin_freq))]\n\nfig, ax = plt.subplots(figsize=(9, 4))\nax.bar(mids, hwe_hist.bin_freq, width=widths, color='darkorange', edgecolor='white', linewidth=0.5)\nax.axvline(x=6, color='red', linestyle='--', linewidth=1.5, label='p = 1e-6 filter')\nax.set_xlabel('-log10(HWE p-value)', fontsize=12)\nax.set_ylabel('Number of Variants', fontsize=12)\nax.set_title('Hardy-Weinberg Equilibrium P-value Distribution', fontsize=14)\nax.legend()\nplt.tight_layout()\nplt.show()"]
  },
  {
   "cell_type": "markdown",
   "id": "md-variant-filter",
   "metadata": {},
   "source": ["### Variant Filtering\n\nWe apply two standard filters:\n- **AF > 1%** — removes rare variants (unreliable frequency estimates at low N)\n- **HWE p-value > 1e-6** — removes variants with extreme genotype imbalances"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-variant-filter",
   "metadata": {},
   "outputs": [],
   "source": ["n_vars_before = mt.count_rows()\n\nmt = mt.filter_rows(mt.variant_qc.AF[1] > 0.01)\nmt = mt.filter_rows(mt.variant_qc.p_value_hwe > 1e-6)\n\nn_vars_after = mt.count_rows()\nprint('Variants before QC: %d' % n_vars_before)\nprint('Variants after QC:  %d' % n_vars_after)\nprint('Removed: %d variants (%.1f%%)' % (\n    n_vars_before - n_vars_after,\n    100 * (n_vars_before - n_vars_after) / n_vars_before if n_vars_before else 0\n))"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-before-after",
   "metadata": {},
   "outputs": [],
   "source": ["# Visual comparison: before vs. after filtering\nfig, ax = plt.subplots(figsize=(7, 4))\nstages = ['Before QC', 'After QC']\nvalues = [n_vars_before, n_vars_after]\ncolors = ['#d9534f', '#5cb85c']\nbars = ax.bar(stages, values, color=colors, edgecolor='white', linewidth=0.8, width=0.5)\nfor bar, v in zip(bars, values):\n    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 50,\n            '%d' % v, ha='center', va='bottom', fontsize=12, fontweight='bold')\nax.set_ylabel('Number of Variants', fontsize=12)\nax.set_title('Variants Before and After QC Filtering', fontsize=14)\nax.set_ylim(0, max(values) * 1.15)\nplt.tight_layout()\nplt.show()"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-final-count",
   "metadata": {},
   "outputs": [],
   "source": ["n_samples, n_variants = mt.count_cols(), mt.count_rows()\nprint('Final dataset after QC:')\nprint('  Samples:  %d' % n_samples)\nprint('  Variants: %d' % n_variants)"]
  },
  {
   "cell_type": "markdown",
   "id": "md-save",
   "metadata": {},
   "source": ["## 4. Save the QC-Filtered MatrixTable\n\nWe write the filtered MatrixTable to disk so that Part 3 can load it directly without re-running QC."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-save",
   "metadata": {},
   "outputs": [],
   "source": ["mt.write('data/1kg_qc.mt', overwrite=True)\nprint('Saved QC-filtered MatrixTable to data/1kg_qc.mt')"]
  },
  {
   "cell_type": "markdown",
   "id": "md-summary",
   "metadata": {},
   "source": ["## Summary\n\nIn this notebook you:\n\n- ✅ Computed per-sample QC metrics and removed low-quality samples (low depth or call rate)\n- ✅ Filtered unreliable genotype calls by allelic balance\n- ✅ Computed per-variant QC metrics and visualized MAF and HWE distributions\n- ✅ Removed rare variants (AF < 1%) and HWE outliers\n- ✅ Saved a clean, filtered MatrixTable ready for association testing\n\n---\n\n**Next:** Open [Part 3 — Association Analysis](https://colab.research.google.com/github/gosborcz/winterschool-gwas-tutorial/blob/main/03_gwas_association.ipynb) to run the GWAS and visualize the results."]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
