{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-title",
   "metadata": {},
   "source": ["# GWAS Tutorial: Data Exploration, QC & Association Analysis\n\nThis notebook walks through a complete genome-wide association study (GWAS) using [Hail](https://hail.is/) and a subset of the 1000 Genomes dataset â€” from raw VCF to association results.\n\n**Sections:**\n1. **Setup** â€” install Hail, download data\n2. **Data Exploration** â€” understand the dataset structure\n3. **Quality Control** â€” filter low-quality samples and variants\n4. **Association Analysis** â€” run GWAS and interpret results\n\n> Run cells from top to bottom. The setup cell installs Hail and downloads ~20 MB of data â€” takes ~2 minutes on first run."]
  },
  {
   "cell_type": "markdown",
   "id": "md-setup-hdr",
   "metadata": {},
   "source": ["## 1. Setup"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-setup",
   "metadata": {},
   "outputs": [],
   "source": ["# Install Java (Hail's Spark backend) and Hail\n!pip install hail -q\n\nimport hail as hl\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom collections import Counter\nfrom pprint import pprint\n\nhl.init()\nfrom hail.plot import show\nhl.plot.output_notebook()\n\n# Download 1000 Genomes data (~20 MB)\nimport os\nos.makedirs('data', exist_ok=True)\nhl.utils.get_1kg('data/')\n\n# Import VCF once, write to Hail's fast binary MatrixTable format\nhl.import_vcf('data/1kg.vcf.bgz').write('data/1kg.mt', overwrite=True)\nmt = hl.read_matrix_table('data/1kg.mt')\n\n# Attach sample phenotypes (population, sex, caffeine consumption, ...)\ntable = hl.import_table('data/1kg_annotations.txt', impute=True).key_by('Sample')\nmt = mt.annotate_cols(pheno=table[mt.s])\nprint('Loaded: %d variants x %d samples' % mt.count())"]
  },
  {
   "cell_type": "markdown",
   "id": "md-section1",
   "metadata": {},
   "source": ["## 2. Data Exploration"]
  },
  {
   "cell_type": "markdown",
   "id": "md-mt-structure",
   "metadata": {},
   "source": ["### The MatrixTable\n\nHail stores genomic data in a **MatrixTable** â€” a 2D structure where:\n\n```\n              Sample1  Sample2  Sample3  ...\n chr1:100 A/T   0/1      0/0      1/1\n chr1:200 G/C   0/0      0/1      0/1\n    ...          ...      ...      ...\n```\n\n- **Rows** = variants (locus + alleles)\n- **Columns** = samples (sample ID `s`)\n- **Entries** = genotype calls (GT, DP, GQ, AD, PL)\n- **Row fields** = variant INFO annotations\n- **Column fields** = sample metadata"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-rows",
   "metadata": {},
   "outputs": [],
   "source": ["mt.rows().select().show(5)  # row key: locus + alleles"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-entries",
   "metadata": {},
   "outputs": [],
   "source": ["mt.entry.take(3)  # entry fields: GT, DP, GQ, AD, PL"]
  },
  {
   "cell_type": "markdown",
   "id": "md-annotations-hdr",
   "metadata": {},
   "source": ["### Sample Annotations\n\nThe annotations file adds per-sample:\n- `SuperPopulation` â€” AFR, AMR, EAS, EUR, SAS\n- `Population` â€” 26 specific populations\n- `isFemale` â€” biological sex\n- `CaffeineConsumption` â€” simulated continuous phenotype (our GWAS trait)\n- `PurpleHair` â€” simulated binary phenotype"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-show-table",
   "metadata": {},
   "outputs": [],
   "source": ["table.show(5, width=120)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-annotate-check",
   "metadata": {},
   "outputs": [],
   "source": ["mt.col.describe()  # confirm pheno fields are attached"]
  },
  {
   "cell_type": "markdown",
   "id": "md-pheno-hdr",
   "metadata": {},
   "source": ["### Phenotype & Population Overview"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-pop-counts",
   "metadata": {},
   "outputs": [],
   "source": ["pop_counts = mt.aggregate_cols(hl.agg.counter(mt.pheno.SuperPopulation))\npprint(pop_counts)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-pop-bar",
   "metadata": {},
   "outputs": [],
   "source": ["pops = sorted(pop_counts.keys())\ncounts = [pop_counts[p] for p in pops]\ncolors = ['#4e9af1', '#f4a261', '#2a9d8f', '#e76f51', '#8ecae6']\n\nfig, ax = plt.subplots(figsize=(8, 4))\nbars = ax.bar(pops, counts, color=colors, edgecolor='white')\nfor bar, c in zip(bars, counts):\n    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1,\n            str(c), ha='center', va='bottom', fontsize=11)\nax.set(xlabel='Super-Population', ylabel='Samples', title='Samples by Super-Population')\nax.set_ylim(0, max(counts) * 1.15)\nplt.tight_layout()\nplt.show()"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-caffeine",
   "metadata": {},
   "outputs": [],
   "source": ["pprint(mt.aggregate_cols(hl.agg.stats(mt.pheno.CaffeineConsumption)))"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-caffeine-hist",
   "metadata": {},
   "outputs": [],
   "source": ["p = hl.plot.histogram(mt.pheno.CaffeineConsumption, bins=30,\n                      title='Caffeine Consumption Distribution', legend='mg/day')\nshow(p)"]
  },
  {
   "cell_type": "markdown",
   "id": "md-variants-hdr",
   "metadata": {},
   "source": ["### Variant Exploration"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-snp-types",
   "metadata": {},
   "outputs": [],
   "source": ["snp_counts = mt.aggregate_rows(\n    hl.agg.counter(hl.Struct(ref=mt.alleles[0], alt=mt.alleles[1]))\n)\nprint('Top 10 allele changes:')\nfor k, v in Counter(snp_counts).most_common(10):\n    print('  %s -> %s: %d' % (k.ref, k.alt, v))"]
  },
  {
   "cell_type": "markdown",
   "id": "md-afs-hdr",
   "metadata": {},
   "source": ["#### Allele Frequency Spectrum\n\nMost variants are rare â€” an L-shaped AFS is the hallmark of healthy genetic data under neutral evolution."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-afs",
   "metadata": {},
   "outputs": [],
   "source": ["afs = mt.aggregate_rows(hl.agg.hist(mt.info.AF[0], 0, 1.0, 50))\nedges, freq = afs.bin_edges, afs.bin_freq\nmids = [(a + b) / 2 for a, b in zip(edges, edges[1:])]\nwidth = (edges[1] - edges[0]) * 0.9\n\nfig, ax = plt.subplots(figsize=(9, 4))\nax.bar(mids, freq, width=width, color='steelblue', edgecolor='white', linewidth=0.5)\nax.set(xlabel='Allele Frequency (AF)', ylabel='Variants', title='Allele Frequency Spectrum')\nax.yaxis.set_major_formatter(lambda x, _: f'{int(x):,}')\nplt.tight_layout()\nplt.show()"]
  },
  {
   "cell_type": "markdown",
   "id": "md-chrom-hdr",
   "metadata": {},
   "source": ["#### Variant Density by Chromosome"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-chrom",
   "metadata": {},
   "outputs": [],
   "source": ["chrom_counts = mt.aggregate_rows(hl.agg.counter(mt.locus.contig))\n\ndef chrom_sort_key(c):\n    n = c.replace('chr', '')\n    return (0, int(n)) if n.isdigit() else (1, n)\n\nchroms = sorted(chrom_counts.keys(), key=chrom_sort_key)\ncnts = [chrom_counts[c] for c in chroms]\n\nfig, ax = plt.subplots(figsize=(13, 4))\nax.bar(range(len(chroms)), cnts, color='teal', edgecolor='white', linewidth=0.5)\nax.set_xticks(range(len(chroms)))\nax.set_xticklabels(chroms, rotation=45, ha='right', fontsize=9)\nax.set(xlabel='Chromosome', ylabel='Variants', title='Variant Density by Chromosome')\nplt.tight_layout()\nplt.show()"]
  },
  {
   "cell_type": "markdown",
   "id": "md-gt-hdr",
   "metadata": {},
   "source": ["#### Genotype Distribution\n\nBecause most variants are rare, the vast majority of entries (variant Ã— sample pairs) should be homozygous reference (0/0)."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-gt-dist",
   "metadata": {},
   "outputs": [],
   "source": ["gt_counts = mt.aggregate_entries(hl.agg.counter(mt.GT.n_alt_alleles()))\n\nlabels = ['Hom Ref (0/0)', 'Het (0/1)', 'Hom Alt (1/1)']\nvalues = [gt_counts.get(k, 0) for k in range(3)]\ntotal = sum(values)\ncolors = ['#4e9af1', '#f4a261', '#e76f51']\n\nfig, (ax, ax2) = plt.subplots(1, 2, figsize=(12, 4))\nax.bar(labels, values, color=colors, edgecolor='white')\nax.set(ylabel='Count', title='Genotype Counts')\nax.yaxis.set_major_formatter(lambda x, _: f'{int(x):,}')\nax2.pie(values, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\nax2.set_title('Genotype Proportions')\nplt.suptitle('Genotype Distribution Across All Entries', fontsize=13)\nplt.tight_layout()\nplt.show()\nfor label, v in zip(labels, values):\n    print('%s: %d (%.1f%%)' % (label, v, 100 * v / total))"]
  },
  {
   "cell_type": "markdown",
   "id": "md-ex1",
   "metadata": {},
   "source": ["---\n**ðŸ” Exercise 1:** The bar chart above shows counts for the 5 super-populations. Modify it to show the breakdown by the more specific `Population` field. How many distinct populations are in this dataset?\n\n> *Hint: change `mt.pheno.SuperPopulation` â†’ `mt.pheno.Population` in the `agg.counter` call and re-run the bar chart.*"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-ex1",
   "metadata": {},
   "outputs": [],
   "source": ["# Exercise 1 â€” your code here\n"]
  },
  {
   "cell_type": "markdown",
   "id": "md-section2",
   "metadata": {},
   "source": ["## 3. Quality Control\n\nBefore running a GWAS, we remove low-quality samples, unreliable genotype calls, and problematic variants. Poor-quality data leads to spurious associations and inflated p-values."]
  },
  {
   "cell_type": "markdown",
   "id": "md-sample-qc-hdr",
   "metadata": {},
   "source": ["### Sample QC\n\n`hl.sample_qc()` computes per-sample metrics:\n\n| Metric | Meaning |\n|---|---|\n| `call_rate` | Fraction of non-missing genotype calls |\n| `dp_stats.mean` | Mean read depth |\n| `gq_stats.mean` | Mean genotype quality |\n\nSamples with low call rate or depth are removed."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-sample-qc",
   "metadata": {},
   "outputs": [],
   "source": ["mt = hl.sample_qc(mt)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-dp-hist",
   "metadata": {},
   "outputs": [],
   "source": ["p = hl.plot.histogram(mt.sample_qc.dp_stats.mean, range=(0, 30), bins=30,\n                      title='Mean Read Depth per Sample', legend='Mean DP')\nshow(p)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-callrate-hist",
   "metadata": {},
   "outputs": [],
   "source": ["p = hl.plot.histogram(mt.sample_qc.call_rate, range=(0.88, 1.0), bins=30,\n                      title='Call Rate per Sample', legend='Call Rate')\nshow(p)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-gq-hist",
   "metadata": {},
   "outputs": [],
   "source": ["p = hl.plot.histogram(mt.sample_qc.gq_stats.mean, range=(10, 70), bins=30,\n                      title='Mean GQ per Sample', legend='Mean GQ')\nshow(p)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-dp-cr-scatter",
   "metadata": {},
   "outputs": [],
   "source": ["p = hl.plot.scatter(mt.sample_qc.dp_stats.mean, mt.sample_qc.call_rate,\n                    xlabel='Mean DP', ylabel='Call Rate',\n                    title='Mean Depth vs. Call Rate')\nshow(p)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-sample-filter",
   "metadata": {},
   "outputs": [],
   "source": ["n_before = mt.count_cols()\nmt = mt.filter_cols((mt.sample_qc.dp_stats.mean >= 4) & (mt.sample_qc.call_rate >= 0.97))\nprint('Samples: %d â†’ %d (removed %d)' % (n_before, mt.count_cols(), n_before - mt.count_cols()))"]
  },
  {
   "cell_type": "markdown",
   "id": "md-ab-hdr",
   "metadata": {},
   "source": ["### Allelic Balance Filter\n\nIndividual genotype calls can be unreliable even in passing samples. The **allelic balance (AB)** â€” fraction of reads supporting the alt allele â€” should be:\n- ~0 for hom ref (0/0)\n- ~0.5 for het (0/1)\n- ~1 for hom alt (1/1)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-ab-filter",
   "metadata": {},
   "outputs": [],
   "source": ["ab = mt.AD[1] / hl.sum(mt.AD)\nfilter_ab = (\n    (mt.GT.is_hom_ref() & (ab <= 0.1)) |\n    (mt.GT.is_het()     & (ab >= 0.25) & (ab <= 0.75)) |\n    (mt.GT.is_hom_var() & (ab >= 0.9))\n)\nfraction_filtered = mt.aggregate_entries(hl.agg.fraction(~filter_ab))\nprint('Setting %.2f%% of entries to missing (failed AB filter).' % (fraction_filtered * 100))\nmt = mt.filter_entries(filter_ab)"]
  },
  {
   "cell_type": "markdown",
   "id": "md-ex2",
   "metadata": {},
   "source": ["---\n**ðŸ” Exercise 2:** The current het allelic balance window is **0.25â€“0.75**. What fraction of entries would *additionally* be removed if you tightened it to **0.30â€“0.70**?\n\n> *Hint: compute `hl.agg.fraction(~filter_ab_strict)` using the stricter condition on `mt` before calling `filter_entries`. The fraction that fails the strict but not the current filter is the difference.*"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-ex2",
   "metadata": {},
   "outputs": [],
   "source": ["# Exercise 2 â€” your code here\n"]
  },
  {
   "cell_type": "markdown",
   "id": "md-variant-qc-hdr",
   "metadata": {},
   "source": ["### Variant QC\n\n`hl.variant_qc()` computes per-variant metrics:\n\n| Metric | Meaning |\n|---|---|\n| `AF[1]` | Alternate allele frequency in this dataset |\n| `call_rate` | Fraction of samples with a call |\n| `p_value_hwe` | Hardy-Weinberg equilibrium test p-value |"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-variant-qc",
   "metadata": {},
   "outputs": [],
   "source": ["mt = hl.variant_qc(mt)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-maf-dist",
   "metadata": {},
   "outputs": [],
   "source": ["af_hist = mt.aggregate_rows(hl.agg.hist(mt.variant_qc.AF[1], 0, 0.5, 50))\nedges, freq = af_hist.bin_edges, af_hist.bin_freq\nmids = [(a + b) / 2 for a, b in zip(edges, edges[1:])]\nwidth = (edges[1] - edges[0]) * 0.9\n\nfig, ax = plt.subplots(figsize=(9, 4))\nax.bar(mids, freq, width=width, color='steelblue', edgecolor='white', linewidth=0.5)\nax.axvline(x=0.01, color='red', linestyle='--', linewidth=1.5, label='AF = 1% filter')\nax.set(xlabel='Alternate Allele Frequency', ylabel='Variants',\n       title='MAF Distribution (before filtering)')\nax.legend()\nplt.tight_layout()\nplt.show()"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-hwe-dist",
   "metadata": {},
   "outputs": [],
   "source": ["hwe_hist = mt.aggregate_rows(\n    hl.agg.filter(hl.is_defined(mt.variant_qc.p_value_hwe),\n                  hl.agg.hist(-hl.log10(mt.variant_qc.p_value_hwe), 0, 10, 40))\n)\nedges, freq = hwe_hist.bin_edges, hwe_hist.bin_freq\nmids = [(a + b) / 2 for a, b in zip(edges, edges[1:])]\nwidth = (edges[1] - edges[0]) * 0.9\n\nfig, ax = plt.subplots(figsize=(9, 4))\nax.bar(mids, freq, width=width, color='darkorange', edgecolor='white', linewidth=0.5)\nax.axvline(x=6, color='red', linestyle='--', linewidth=1.5, label='p = 1e-6 filter')\nax.set(xlabel='-log10(HWE p-value)', ylabel='Variants',\n       title='HWE P-value Distribution (before filtering)')\nax.legend()\nplt.tight_layout()\nplt.show()"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-variant-filter",
   "metadata": {},
   "outputs": [],
   "source": ["n_vars_before = mt.count_rows()\nmt = mt.filter_rows((mt.variant_qc.AF[1] > 0.01) & (mt.variant_qc.p_value_hwe > 1e-6))\nn_vars_after = mt.count_rows()\nprint('Variants: %d â†’ %d (removed %d, %.1f%%)' % (\n    n_vars_before, n_vars_after,\n    n_vars_before - n_vars_after,\n    100 * (n_vars_before - n_vars_after) / n_vars_before\n))"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-before-after",
   "metadata": {},
   "outputs": [],
   "source": ["fig, ax = plt.subplots(figsize=(6, 4))\nbars = ax.bar(['Before QC', 'After QC'], [n_vars_before, n_vars_after],\n              color=['#d9534f', '#5cb85c'], edgecolor='white', width=0.5)\nfor bar, v in zip(bars, [n_vars_before, n_vars_after]):\n    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 20,\n            f'{v:,}', ha='center', va='bottom', fontsize=12, fontweight='bold')\nax.set(ylabel='Variants', title='Variants Before and After QC')\nax.set_ylim(0, n_vars_before * 1.15)\nplt.tight_layout()\nplt.show()"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-final-count",
   "metadata": {},
   "outputs": [],
   "source": ["n_variants, n_samples = mt.count()\nprint('After QC: %d variants x %d samples' % (n_variants, n_samples))"]
  },
  {
   "cell_type": "markdown",
   "id": "md-section3",
   "metadata": {},
   "source": ["## 4. Association Analysis"]
  },
  {
   "cell_type": "markdown",
   "id": "md-pca-hdr",
   "metadata": {},
   "source": ["### Population Stratification â€” PCA\n\nThe 1000 Genomes dataset spans 5 continental populations (AFR, AMR, EAS, EUR, SAS). If we ignore this, variants that differ in frequency across populations will appear associated with caffeine â€” not because they affect it, but because ancestry correlates with both genotype and phenotype.\n\nWe compute **Principal Components (PCs)** of the genotype matrix to capture ancestry, then include them as covariates in regression."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-pca-run",
   "metadata": {},
   "outputs": [],
   "source": ["eigenvalues, pcs, _ = hl.hwe_normalized_pca(mt.GT)\npprint(eigenvalues[:5])  # variance explained by each PC"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-pca-annotate",
   "metadata": {},
   "outputs": [],
   "source": ["mt = mt.annotate_cols(scores=pcs[mt.s].scores)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-pca-plot",
   "metadata": {},
   "outputs": [],
   "source": ["p = hl.plot.scatter(mt.scores[0], mt.scores[1],\n                    label=mt.pheno.SuperPopulation,\n                    title='PCA â€” PC1 vs PC2', xlabel='PC1', ylabel='PC2')\nshow(p)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-pca-pc3",
   "metadata": {},
   "outputs": [],
   "source": ["p = hl.plot.scatter(mt.scores[1], mt.scores[2],\n                    label=mt.pheno.SuperPopulation,\n                    title='PCA â€” PC2 vs PC3', xlabel='PC2', ylabel='PC3')\nshow(p)"]
  },
  {
   "cell_type": "markdown",
   "id": "md-naive-gwas-hdr",
   "metadata": {},
   "source": ["### Naive GWAS (no covariates)\n\nAs a baseline, we run linear regression without any population covariates â€” this will show inflation because ancestry is not accounted for."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-naive-gwas",
   "metadata": {},
   "outputs": [],
   "source": ["gwas_naive = hl.linear_regression_rows(\n    y=mt.pheno.CaffeineConsumption,\n    x=mt.GT.n_alt_alleles(),\n    covariates=[1.0]  # intercept only\n)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-naive-qq",
   "metadata": {},
   "outputs": [],
   "source": ["p = hl.plot.qq(gwas_naive.p_value, title='QQ Plot â€” naive (no covariates)')\nshow(p)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-naive-manhattan",
   "metadata": {},
   "outputs": [],
   "source": ["p = hl.plot.manhattan(gwas_naive.p_value, title='Manhattan Plot â€” naive (no covariates)')\nshow(p)"]
  },
  {
   "cell_type": "markdown",
   "id": "md-lambda-explain",
   "metadata": {},
   "source": ["**Genomic inflation factor (Î»)** is shown in the QQ plot. It measures how inflated the test statistics are:\n- Î» â‰ˆ 1.0 â†’ well-calibrated\n- Î» > 1.05 â†’ inflation (likely population stratification)\n- Î» < 1.0 â†’ deflation (over-correction)\n\nThe naive GWAS should show Î» >> 1."]
  },
  {
   "cell_type": "markdown",
   "id": "md-corrected-gwas-hdr",
   "metadata": {},
   "source": ["### Corrected GWAS (sex + PC1â€“3 as covariates)\n\nIncluding PCs as covariates removes the ancestry signal and brings Î» close to 1."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-corrected-gwas",
   "metadata": {},
   "outputs": [],
   "source": ["gwas = hl.linear_regression_rows(\n    y=mt.pheno.CaffeineConsumption,\n    x=mt.GT.n_alt_alleles(),\n    covariates=[1.0, mt.pheno.isFemale, mt.scores[0], mt.scores[1], mt.scores[2]]\n)\nprint('Tested: %d variants' % gwas.count())"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-qq-corrected",
   "metadata": {},
   "outputs": [],
   "source": ["p = hl.plot.qq(gwas.p_value, title='QQ Plot â€” corrected (sex + PC1-3)')\nshow(p)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-manhattan-corrected",
   "metadata": {},
   "outputs": [],
   "source": ["p = hl.plot.manhattan(gwas.p_value, title='Manhattan Plot â€” corrected (sex + PC1-3)')\nshow(p)"]
  },
  {
   "cell_type": "markdown",
   "id": "md-top-hits-hdr",
   "metadata": {},
   "source": ["### Top Hits\n\nSince `CaffeineConsumption` is a simulated phenotype, we don't expect real hits â€” but this is the workflow you'd use on real data."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-top-hits",
   "metadata": {},
   "outputs": [],
   "source": ["gwas.order_by(gwas.p_value).select('p_value', 'beta', 'standard_error', 't_stat').show(20, width=120)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-top-hits-viz",
   "metadata": {},
   "outputs": [],
   "source": ["top = gwas.order_by(gwas.p_value).take(20)\nbetas = np.array([r.beta for r in top])\nses   = np.array([r.standard_error for r in top])\nlabels = ['%s/%s' % (r.locus, r.alleles[1]) for r in top]\n\nfig, ax = plt.subplots(figsize=(8, 7))\ny = np.arange(len(top))\nax.errorbar(betas, y, xerr=1.96 * ses, fmt='o', color='steelblue',\n            capsize=3, linewidth=1, markersize=5)\nax.axvline(0, color='grey', linestyle='--', linewidth=1)\nax.set_yticks(y)\nax.set_yticklabels(labels, fontsize=8)\nax.set(xlabel='Effect size (beta) Â± 95% CI', title='Top 20 Variants by P-value')\nax.invert_yaxis()\nplt.tight_layout()\nplt.show()"]
  },
  {
   "cell_type": "markdown",
   "id": "md-ex3",
   "metadata": {},
   "source": ["---\n**ðŸ” Exercise 3:** We used `hl.linear_regression_rows` for the continuous `CaffeineConsumption` trait. The dataset also has a binary trait: `PurpleHair`. Run a **logistic GWAS** using `hl.logistic_regression_rows` and plot the Manhattan. Do the top hits overlap with caffeine?\n\n> *Starter code:*\n> ```python\n> gwas_binary = hl.logistic_regression_rows(\n>     test='wald',\n>     y=mt.pheno.PurpleHair,\n>     x=mt.GT.n_alt_alleles(),\n>     covariates=[1.0, mt.pheno.isFemale, mt.scores[0], mt.scores[1], mt.scores[2]]\n> )\n> ```"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-ex3",
   "metadata": {},
   "outputs": [],
   "source": ["# Exercise 3 â€” your code here\n"]
  },
  {
   "cell_type": "markdown",
   "id": "md-summary",
   "metadata": {},
   "source": ["## Summary\n\nIn this tutorial you:\n\n- âœ… Downloaded and imported the 1000 Genomes VCF into a Hail MatrixTable\n- âœ… Explored the dataset: MatrixTable structure, population composition, allele frequency spectrum, genotype distribution\n- âœ… Applied sample QC (depth, call rate), allelic balance filtering, and variant QC (MAF, HWE)\n- âœ… Ran PCA to capture population structure\n- âœ… Compared a naive vs. covariate-corrected GWAS, and observed the effect of stratification on Î»\n- âœ… Identified and visualised the top associated variants"]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
