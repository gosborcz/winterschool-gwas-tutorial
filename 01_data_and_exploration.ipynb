{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-title",
   "metadata": {},
   "source": ["# GWAS Tutorial — Part 1: Data Loading & Exploration\n\nThis notebook introduces [Hail](https://hail.is/), a Python library for scalable genomic data analysis, and walks you through downloading, importing, and exploring the **1000 Genomes dataset**.\n\nThis is the first of three notebooks:\n\n| Notebook | Topic |\n|---|---|\n| **Part 1 (this notebook)** | Data loading & exploration |\n| **Part 2** | Quality control |\n| **Part 3** | Association analysis & results |\n\n> **Note:** Run cells from top to bottom. The first code cell installs dependencies and downloads ~20 MB of data — this takes a couple of minutes the first time."]
  },
  {
   "cell_type": "markdown",
   "id": "md-setup-header",
   "metadata": {},
   "source": ["## Setup\n\nHail requires Java to run its Spark backend. The cell below installs OpenJDK 11 and Hail in this Colab environment."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-install",
   "metadata": {},
   "outputs": [],
   "source": ["!apt-get install -y openjdk-11-jdk-headless -q\n!pip install hail -q\nprint('Installation complete!')"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-init",
   "metadata": {},
   "outputs": [],
   "source": ["import hail as hl\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as ticker\nfrom collections import Counter\nfrom pprint import pprint\n\nhl.init()\nfrom hail.plot import show\nhl.plot.output_notebook()\nprint('Hail initialized.')"]
  },
  {
   "cell_type": "markdown",
   "id": "md-data-header",
   "metadata": {},
   "source": ["## 1. Download the 1000 Genomes Dataset\n\nWe use a publicly available subset of the [1000 Genomes Project](https://www.internationalgenome.org/), which contains genomic variants from individuals across 26 world populations.\n\n`hl.utils.get_1kg()` downloads:\n- `1kg.vcf.bgz` — a compressed VCF file with genotype calls\n- `1kg_annotations.txt` — sample phenotypes and population labels"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-download",
   "metadata": {},
   "outputs": [],
   "source": ["import os\nos.makedirs('data', exist_ok=True)\nhl.utils.get_1kg('data/')"]
  },
  {
   "cell_type": "markdown",
   "id": "md-import-header",
   "metadata": {},
   "source": ["## 2. Import the VCF and Create a MatrixTable\n\nHail works with its own binary format called a **MatrixTable**. We import the VCF once and write it to disk — subsequent reads are much faster than re-parsing the VCF each time."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-import-vcf",
   "metadata": {},
   "outputs": [],
   "source": ["hl.import_vcf('data/1kg.vcf.bgz').write('data/1kg.mt', overwrite=True)\nmt = hl.read_matrix_table('data/1kg.mt')\nn_vars, n_samples = mt.count()\nprint('Loaded: %d variants x %d samples' % (n_vars, n_samples))"]
  },
  {
   "cell_type": "markdown",
   "id": "md-mt-structure",
   "metadata": {},
   "source": ["## 3. The MatrixTable: Hail's Core Data Structure\n\nA **MatrixTable** organizes genomic data as a 2D matrix:\n\n```\n              Sample1  Sample2  Sample3  ...\n chr1:100 A/T   0/1      0/0      1/1\n chr1:200 G/C   0/0      0/1      0/1\n chr2:500 A/G   1/1      0/1      0/0\n    ...          ...      ...      ...\n```\n\n- **Rows** = variants (identified by locus + alleles)\n- **Columns** = samples (identified by sample ID `s`)\n- **Entries** = genotype calls (GT, DP, GQ, AD, PL per variant-sample pair)\n- **Row fields** = variant-level INFO annotations\n- **Column fields** = sample metadata (we add these next)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-rows",
   "metadata": {},
   "outputs": [],
   "source": ["# Row key: locus (chromosome + position) and alleles (ref, alt)\nmt.rows().select().show(5)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-entries",
   "metadata": {},
   "outputs": [],
   "source": ["# Entry fields: GT=genotype, DP=read depth, GQ=genotype quality, AD=allele depths\nmt.entry.take(3)"]
  },
  {
   "cell_type": "markdown",
   "id": "md-annotations-header",
   "metadata": {},
   "source": ["## 4. Sample Annotations\n\nThe annotations file contains one row per sample with:\n- `SuperPopulation` — one of 5 continental groups (AFR, AMR, EAS, EUR, SAS)\n- `Population` — one of 26 specific populations\n- `isFemale` — biological sex\n- `CaffeineConsumption` — a simulated continuous phenotype (our GWAS trait)\n- `PurpleHair` — a simulated binary phenotype\n\nWe load this table and join it to the MatrixTable columns by sample ID."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-load-table",
   "metadata": {},
   "outputs": [],
   "source": ["table = hl.import_table('data/1kg_annotations.txt', impute=True).key_by('Sample')\ntable.describe()"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-show-table",
   "metadata": {},
   "outputs": [],
   "source": ["table.show(5, width=120)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-annotate",
   "metadata": {},
   "outputs": [],
   "source": ["mt = mt.annotate_cols(pheno=table[mt.s])\nmt.col.describe()"]
  },
  {
   "cell_type": "markdown",
   "id": "md-pheno-header",
   "metadata": {},
   "source": ["## 5. Phenotype & Population Overview\n\nLet's look at the distribution of samples across super-populations and explore the phenotype of interest."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-pop-counts",
   "metadata": {},
   "outputs": [],
   "source": ["pop_counts = mt.aggregate_cols(hl.agg.counter(mt.pheno.SuperPopulation))\npprint(pop_counts)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-pop-bar",
   "metadata": {},
   "outputs": [],
   "source": ["fig, ax = plt.subplots(figsize=(8, 4))\npops = sorted(pop_counts.keys())\ncounts = [pop_counts[p] for p in pops]\ncolors = ['#4e9af1', '#f4a261', '#2a9d8f', '#e76f51', '#8ecae6']\nbars = ax.bar(pops, counts, color=colors, edgecolor='white', linewidth=0.8)\nfor bar, c in zip(bars, counts):\n    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1,\n            str(c), ha='center', va='bottom', fontsize=11)\nax.set_xlabel('Super-Population', fontsize=12)\nax.set_ylabel('Number of Samples', fontsize=12)\nax.set_title('Sample Counts by Super-Population', fontsize=14)\nax.set_ylim(0, max(counts) * 1.15)\nplt.tight_layout()\nplt.show()"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-caffeine",
   "metadata": {},
   "outputs": [],
   "source": ["# Summary statistics for caffeine consumption\ncaff_stats = mt.aggregate_cols(hl.agg.stats(mt.pheno.CaffeineConsumption))\npprint(caff_stats)"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-caffeine-hist",
   "metadata": {},
   "outputs": [],
   "source": ["caff_values = mt.aggregate_cols(hl.agg.collect(mt.pheno.CaffeineConsumption))\nfig, ax = plt.subplots(figsize=(8, 4))\nax.hist(caff_values, bins=30, color='steelblue', edgecolor='white')\nax.set_xlabel('Caffeine Consumption (mg/day)', fontsize=12)\nax.set_ylabel('Number of Samples', fontsize=12)\nax.set_title('Distribution of Caffeine Consumption Phenotype', fontsize=14)\nplt.tight_layout()\nplt.show()"]
  },
  {
   "cell_type": "markdown",
   "id": "md-variants-header",
   "metadata": {},
   "source": ["## 6. Variant Exploration\n\nNow let's dig into the genomic variants — their types, allele frequencies, and distribution across the genome."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-snp-types",
   "metadata": {},
   "outputs": [],
   "source": ["# Count all unique ref->alt substitution pairs\nsnp_counts = mt.aggregate_rows(\n    hl.agg.counter(hl.Struct(ref=mt.alleles[0], alt=mt.alleles[1]))\n)\nprint('Top 10 most common allele changes:')\nfor change, count in Counter(snp_counts).most_common(10):\n    print('  %s -> %s: %d' % (change.ref, change.alt, count))"]
  },
  {
   "cell_type": "markdown",
   "id": "md-titv",
   "metadata": {},
   "source": ["### Transition / Transversion Ratio (Ti/Tv)\n\n**Transitions (Ti)** are purine↔purine or pyrimidine↔pyrimidine: A↔G, C↔T  \n**Transversions (Tv)** are purine↔pyrimidine: A↔C, A↔T, G↔C, G↔T\n\nFor whole-genome sequencing, a Ti/Tv of **~2.0–2.1** is expected. Values outside this range can indicate sequencing artifacts."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-titv",
   "metadata": {},
   "outputs": [],
   "source": ["transitions = {'A>G', 'G>A', 'C>T', 'T>C'}\ntransversions = {'A>C', 'A>T', 'G>C', 'G>T', 'C>A', 'T>A', 'C>G', 'T>G'}\n\nti_count = sum(v for k, v in snp_counts.items() if '%s>%s' % (k.ref, k.alt) in transitions)\ntv_count = sum(v for k, v in snp_counts.items() if '%s>%s' % (k.ref, k.alt) in transversions)\n\nprint('Transitions:   %d' % ti_count)\nprint('Transversions: %d' % tv_count)\nprint('Ti/Tv ratio:   %.3f' % (ti_count / tv_count if tv_count else float('nan')))"]
  },
  {
   "cell_type": "markdown",
   "id": "md-afs",
   "metadata": {},
   "source": ["### Allele Frequency Spectrum (AFS)\n\nThe AFS shows the distribution of variant allele frequencies. In any population, most variants are **rare**, as predicted by population genetics theory — this L-shaped distribution is a hallmark of healthy genetic data.\n\nWe use the `AF` field from the VCF INFO column, which gives the allele frequency in the original 1000 Genomes cohort."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-afs",
   "metadata": {},
   "outputs": [],
   "source": ["afs = mt.aggregate_rows(hl.agg.hist(mt.info.AF[0], 0, 1.0, 50))\n\nedges = afs.bin_edges\nwidths = [(edges[i+1] - edges[i]) * 0.9 for i in range(len(afs.bin_freq))]\nmids = [(edges[i] + edges[i+1]) / 2 for i in range(len(afs.bin_freq))]\n\nfig, ax = plt.subplots(figsize=(9, 4))\nax.bar(mids, afs.bin_freq, width=widths, color='steelblue', edgecolor='white', linewidth=0.5)\nax.set_xlabel('Allele Frequency (AF)', fontsize=12)\nax.set_ylabel('Number of Variants', fontsize=12)\nax.set_title('Allele Frequency Spectrum', fontsize=14)\nax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: '%d' % int(x)))\nplt.tight_layout()\nplt.show()\n\nrare = sum(f for m, f in zip(mids, afs.bin_freq) if m < 0.05)\ntotal = sum(afs.bin_freq)\nprint('Variants with AF < 5%%: %d (%.1f%%)' % (rare, 100 * rare / total if total else 0))"]
  },
  {
   "cell_type": "markdown",
   "id": "md-chrom",
   "metadata": {},
   "source": ["### Variant Density by Chromosome\n\nLonger chromosomes generally carry more variants. This plot shows how the ~10k variants in this subset are distributed across the genome."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-chrom",
   "metadata": {},
   "outputs": [],
   "source": ["chrom_counts = mt.aggregate_rows(hl.agg.counter(mt.locus.contig))\n\ndef chrom_sort_key(c):\n    c = c.replace('chr', '')\n    try:\n        return (0, int(c))\n    except ValueError:\n        return (1, c)\n\nchroms = sorted(chrom_counts.keys(), key=chrom_sort_key)\ncnts = [chrom_counts[c] for c in chroms]\n\nfig, ax = plt.subplots(figsize=(13, 4))\nax.bar(range(len(chroms)), cnts, color='teal', edgecolor='white', linewidth=0.5)\nax.set_xticks(range(len(chroms)))\nax.set_xticklabels(chroms, rotation=45, ha='right', fontsize=9)\nax.set_xlabel('Chromosome', fontsize=12)\nax.set_ylabel('Number of Variants', fontsize=12)\nax.set_title('Variant Density by Chromosome', fontsize=14)\nplt.tight_layout()\nplt.show()"]
  },
  {
   "cell_type": "markdown",
   "id": "md-gt",
   "metadata": {},
   "source": ["### Genotype Distribution\n\nFor each variant-sample pair, the genotype is:\n- **0/0** — homozygous reference (both alleles are the reference)\n- **0/1** — heterozygous (one ref, one alt allele)\n- **1/1** — homozygous alternate\n\nBecause most variants are rare, the vast majority of entries should be homozygous reference."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code-gt-dist",
   "metadata": {},
   "outputs": [],
   "source": ["gt_counts = mt.aggregate_entries(hl.agg.counter(mt.GT.n_alt_alleles()))\n\nlabels = {0: 'Hom Ref (0/0)', 1: 'Het (0/1)', 2: 'Hom Alt (1/1)'}\nvalues = [gt_counts.get(k, 0) for k in [0, 1, 2]]\ntotal = sum(values)\ncolors = ['#4e9af1', '#f4a261', '#e76f51']\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\nax = axes[0]\nax.bar([labels[k] for k in [0, 1, 2]], values, color=colors, edgecolor='white')\nax.set_ylabel('Count', fontsize=12)\nax.set_title('Genotype Counts', fontsize=14)\nax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: '%d' % int(x)))\n\nax2 = axes[1]\nax2.pie(values, labels=[labels[k] for k in [0, 1, 2]], colors=colors,\n        autopct='%1.1f%%', startangle=90)\nax2.set_title('Genotype Proportions', fontsize=14)\n\nplt.suptitle('Genotype Distribution Across All Entries', fontsize=13)\nplt.tight_layout()\nplt.show()\n\nfor k in [0, 1, 2]:\n    print('%s: %d (%.1f%%)' % (labels[k], gt_counts.get(k, 0), 100 * gt_counts.get(k, 0) / total if total else 0))"]
  },
  {
   "cell_type": "markdown",
   "id": "md-summary",
   "metadata": {},
   "source": ["## Summary\n\nIn this notebook you:\n\n- ✅ Installed Hail and initialized it in Colab\n- ✅ Downloaded and imported the 1000 Genomes VCF into a Hail MatrixTable\n- ✅ Learned the MatrixTable structure (rows/cols/entries)\n- ✅ Joined sample phenotypes and population labels\n- ✅ Visualized population composition, the allele frequency spectrum, Ti/Tv ratio, chromosome-level variant density, and genotype distribution\n\n---\n\n**Next:** Open [Part 2 — Quality Control](https://colab.research.google.com/github/gosborcz/winterschool-gwas-tutorial/blob/main/02_quality_control.ipynb) to filter low-quality samples and variants before running the GWAS."]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
